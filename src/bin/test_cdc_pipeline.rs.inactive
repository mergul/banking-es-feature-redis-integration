use banking_es::infrastructure::cdc_debezium::CDCOutboxRepository;
use banking_es::infrastructure::connection_pool_partitioning::PartitionedPools;
use sqlx::PgPool;
use std::sync::Arc;
use uuid::Uuid;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging
    tracing_subscriber::fmt::init();

    println!("üîç Testing CDC Pipeline");
    println!("======================");

    // Create database pool
    let database_url = "postgresql://postgres:Francisco1@localhost:5432/banking_es";
    let pool = PgPool::connect(database_url).await?;

    // Create partitioned pools using environment variables
    let config = banking_es::infrastructure::connection_pool_partitioning::PoolPartitioningConfig {
        database_url: database_url.to_string(),
        write_pool_max_connections: std::env::var("DB_MAX_CONNECTIONS")
            .unwrap_or_else(|_| "80".to_string())
            .parse()
            .unwrap_or(80)
            / 3, // Write pool gets 1/3 of total connections
        write_pool_min_connections: std::env::var("DB_MIN_CONNECTIONS")
            .unwrap_or_else(|_| "20".to_string())
            .parse()
            .unwrap_or(20)
            / 3, // Write pool gets 1/3 of min connections
        read_pool_max_connections: std::env::var("DB_MAX_CONNECTIONS")
            .unwrap_or_else(|_| "80".to_string())
            .parse()
            .unwrap_or(80)
            * 2
            / 3, // Read pool gets 2/3 of total connections
        read_pool_min_connections: std::env::var("DB_MIN_CONNECTIONS")
            .unwrap_or_else(|_| "20".to_string())
            .parse()
            .unwrap_or(20)
            * 2
            / 3, // Read pool gets 2/3 of min connections
        acquire_timeout_secs: std::env::var("DB_ACQUIRE_TIMEOUT")
            .unwrap_or_else(|_| "30".to_string())
            .parse()
            .unwrap_or(30),
        write_idle_timeout_secs: std::env::var("DB_IDLE_TIMEOUT")
            .unwrap_or_else(|_| "600".to_string())
            .parse()
            .unwrap_or(600),
        read_idle_timeout_secs: std::env::var("DB_IDLE_TIMEOUT")
            .unwrap_or_else(|_| "900".to_string())
            .parse()
            .unwrap_or(900),
        write_max_lifetime_secs: std::env::var("DB_MAX_LIFETIME")
            .unwrap_or_else(|_| "1800".to_string())
            .parse()
            .unwrap_or(1800),
        read_max_lifetime_secs: std::env::var("DB_MAX_LIFETIME")
            .unwrap_or_else(|_| "3600".to_string())
            .parse()
            .unwrap_or(3600),
    };
    let partitioned_pools = Arc::new(PartitionedPools::new(config).await?);

    // Create CDC outbox repository
    let outbox_repo = Arc::new(CDCOutboxRepository::new(partitioned_pools.clone()));

    // Check current count in kafka_outbox_cdc
    let current_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM kafka_outbox_cdc")
        .fetch_one(&pool)
        .await?;

    println!("üìä Current messages in kafka_outbox_cdc: {}", current_count);

    // Insert a test message into kafka_outbox_cdc
    let test_id = Uuid::new_v4();
    let test_aggregate_id = Uuid::new_v4();
    let test_event_id = Uuid::new_v4();

    println!("üìù Inserting test message with ID: {}", test_id);

    // Create a real AccountCreated event
    let account_created_event = banking_es::domain::AccountEvent::AccountCreated {
        account_id: test_aggregate_id,
        owner_name: "TestUser".to_string(),
        initial_balance: rust_decimal::Decimal::new(1000, 0), // 1000.00
    };

    // Serialize the event using bincode
    let event_payload = bincode::serialize(&account_created_event)
        .expect("Failed to serialize AccountCreated event");

    sqlx::query!(
        r#"
        INSERT INTO kafka_outbox_cdc (id, aggregate_id, event_id, event_type, payload, topic, metadata, created_at, updated_at)
        VALUES ($1, $2, $3, $4, $5, $6, $7, NOW(), NOW())
        "#,
        test_id,
        test_aggregate_id,
        test_event_id,
        "AccountCreated",
        event_payload,
        "banking-es.public.kafka_outbox_cdc",
        serde_json::json!({"test": true})
    )
    .execute(&pool)
    .await?;

    println!("‚úÖ Test message inserted successfully");

    // Wait a moment for Debezium to capture the change
    println!("‚è≥ Waiting 3 seconds for Debezium to capture the change...");
    tokio::time::sleep(tokio::time::Duration::from_secs(3)).await;

    // Check if the message was processed (should be deleted if processed)
    let new_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM kafka_outbox_cdc")
        .fetch_one(&pool)
        .await?;

    println!(
        "üìä Messages in kafka_outbox_cdc after processing: {}",
        new_count
    );

    // Check if our test message is still there
    let test_message_exists: bool =
        sqlx::query_scalar("SELECT EXISTS(SELECT 1 FROM kafka_outbox_cdc WHERE id = $1)")
            .bind(test_id)
            .fetch_one(&pool)
            .await?;

    if test_message_exists {
        println!(
            "‚ö†Ô∏è Test message still exists in kafka_outbox_cdc - CDC processing may not be working"
        );
    } else {
        println!("‚úÖ Test message was processed and removed from kafka_outbox_cdc");
    }

    // Check if any projections were updated
    let projection_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM account_projections")
        .fetch_one(&pool)
        .await?;

    println!(
        "üìä Total projections in account_projections: {}",
        projection_count
    );

    // Clean up test message if it still exists
    if test_message_exists {
        sqlx::query!("DELETE FROM kafka_outbox_cdc WHERE id = $1", test_id)
            .execute(&pool)
            .await?;
        println!("üßπ Cleaned up test message");
    }

    println!("üéØ CDC Pipeline Test Complete");
    Ok(())
}
