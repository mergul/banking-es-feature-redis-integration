use banking_es::infrastructure::cache_service::{CacheConfig, CacheService};
use banking_es::infrastructure::cdc_debezium::{CDCOutboxRepository, DebeziumConfig};
use banking_es::infrastructure::cdc_service_manager::CDCServiceManager;
use banking_es::infrastructure::connection_pool_partitioning::{
    OperationType, PartitionedPools, PoolPartitioningConfig, PoolSelector,
};
use banking_es::infrastructure::kafka_abstraction::{KafkaConfig, KafkaConsumer, KafkaProducer};
use banking_es::infrastructure::projections::ProjectionStore;
use banking_es::infrastructure::redis_abstraction::RealRedisClient;
use redis::Client;
use sqlx::PgPool;
use std::sync::Arc;
use std::time::Duration;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging
    tracing_subscriber::fmt::init();

    println!("üîç CDC Pipeline Test");
    println!("===================");

    // Create database pool
    let database_url = "postgresql://postgres:Francisco1@localhost:5432/banking_es";
    let pool = PgPool::connect(database_url).await?;

    // Create partitioned pools
    let pool_config = PoolPartitioningConfig {
        database_url: database_url.to_string(),
        write_pool_max_connections: 10,
        write_pool_min_connections: 2,
        read_pool_max_connections: 20,
        read_pool_min_connections: 5,
        acquire_timeout_secs: 10,
        read_max_lifetime_secs: 20,
        write_idle_timeout_secs: 10,
        read_idle_timeout_secs: 10,
        write_max_lifetime_secs: 20,
    };
    let pools = Arc::new(PartitionedPools::new(pool_config).await?);

    // Create Redis client
    let redis_url = "redis://localhost:6379";
    let redis_client = Client::open(redis_url)?;
    let redis_client_trait = RealRedisClient::new(redis_client, None);
    let cache_config = CacheConfig::default();
    let cache_service = Arc::new(CacheService::new(redis_client_trait, cache_config));

    // Create projection store
    let projection_store = Arc::new(ProjectionStore::new(pool.clone()));

    // Create Kafka producer and consumer
    let kafka_config = KafkaConfig::default();
    let kafka_producer = KafkaProducer::new(kafka_config.clone())?;
    let kafka_consumer = KafkaConsumer::new(kafka_config)?;

    // Create CDC outbox repository
    let outbox_repo = Arc::new(CDCOutboxRepository::new(pools.clone()));

    // Create Debezium config
    let debezium_config = DebeziumConfig::default();

    // Create CDC service manager
    let mut cdc_service_manager = CDCServiceManager::new(
        debezium_config.clone(),
        outbox_repo,
        kafka_producer,
        kafka_consumer,
        cache_service,
        pools.clone(),
        None, // metrics
        None, // consistency manager
    )?;

    // Start CDC service
    println!("üöÄ Starting CDC Service Manager...");
    cdc_service_manager.start().await?;
    println!("‚úÖ CDC Service Manager started");

    // Wait for CDC to initialize
    tokio::time::sleep(Duration::from_secs(5)).await;

    // Test 1: Check if Debezium connector is running
    println!("\nüìä Test 1: Checking Debezium Connector Status");
    println!("=============================================");

    // Try to get Debezium config
    let debezium_config_json = cdc_service_manager.get_debezium_config();
    println!(
        "Debezium Config: {}",
        serde_json::to_string_pretty(&debezium_config_json)?
    );

    // Test 2: Check if CDC table exists and has data
    println!("\nüìä Test 2: Checking CDC Table");
    println!("=============================");

    let write_pool = pools.select_pool(OperationType::Write);

    // Check if table exists
    let table_exists = sqlx::query!(
        "SELECT EXISTS (
            SELECT FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_name = 'kafka_outbox_cdc'
        )"
    )
    .fetch_one(write_pool)
    .await?;

    if table_exists.exists.unwrap_or(false) {
        println!("‚úÖ CDC table exists");

        // Count messages in the table
        let message_count = sqlx::query!("SELECT COUNT(*) as count FROM kafka_outbox_cdc")
            .fetch_one(write_pool)
            .await?;

        println!(
            "üìä Total messages in CDC table: {}",
            message_count.count.unwrap_or(0)
        );

        // Get recent messages
        let recent_messages = sqlx::query!(
            "SELECT id, aggregate_id, event_type, created_at 
             FROM kafka_outbox_cdc 
             ORDER BY created_at DESC 
             LIMIT 5"
        )
        .fetch_all(write_pool)
        .await?;

        println!("üìù Recent messages:");
        for msg in recent_messages {
            println!(
                "  - ID: {}, Aggregate: {}, Event: {}, Created: {}",
                msg.id, msg.aggregate_id, msg.event_type, msg.created_at
            );
        }
    } else {
        println!("‚ùå CDC table does not exist");
    }

    // Test 3: Check Kafka topics
    println!("\nüìä Test 3: Checking Kafka Topics");
    println!("=================================");

    // This would require admin client to list topics
    // For now, just print the expected topic name
    let expected_topic = format!(
        "{}.{}",
        debezium_config.topic_prefix, debezium_config.table_include_list
    );
    println!("Expected CDC topic: {}", expected_topic);
    println!(
        "Note: Use 'kafka-topics.sh --list --bootstrap-server localhost:9092' to check topics"
    );

    // Test 4: Check if Debezium connector is registered
    println!("\nüìä Test 4: Checking Debezium Connector");
    println!("=======================================");
    println!("Note: Use 'curl -X GET http://localhost:8083/connectors' to check connectors");
    println!("Note: Use 'curl -X GET http://localhost:8083/connectors/banking-es-connector/status' to check status");

    // Stop CDC service
    println!("\nüõë Stopping CDC Service Manager...");
    cdc_service_manager.stop().await?;
    println!("‚úÖ CDC Service Manager stopped");

    println!("\n‚úÖ CDC Pipeline Test completed!");
    Ok(())
}
